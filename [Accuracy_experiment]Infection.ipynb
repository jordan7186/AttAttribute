{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy experiments with Infection Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the utility functions\n",
    "from attention_analysis_utils import (\n",
    "    get_attention_raw_dict,\n",
    "    process_attention_dict,\n",
    "    get_computation_graph,\n",
    "    get_nodes_per_level_from_comp_graph_full,\n",
    "    get_attention_raw_dict_multihead,\n",
    "    reindex_nodes_per_level,\n",
    "    translate_comp_graph,\n",
    "    get_att_dict_per_layer,\n",
    "    return_edges_in_k_hop,\n",
    "    get_ATTATTTRIBUTE_edge,\n",
    "    get_AVGATT_edge,\n",
    "    average_attention_heads,\n",
    ")\n",
    "\n",
    "from torch_geometric.utils import get_num_hops\n",
    "from visualization_utils import (\n",
    "    visualize_computation_graph,\n",
    ")\n",
    "import torch\n",
    "from typing import Tuple\n",
    "\n",
    "def get_edge_scores(\n",
    "    target_edge: Tuple, comp_graph, comp_graph_new, layer_att_dict, att\n",
    "):\n",
    "    assert type(target_edge) == tuple, \"target_edge must be a tuple\"\n",
    "    # Get ATTATTRIBUTE & ATTATTRIBUTE_sim scores\n",
    "    attattribute, attattribute_sim = get_ATTATTTRIBUTE_edge(\n",
    "        comp_graph=comp_graph,\n",
    "        comp_graph_new=comp_graph_new,\n",
    "        layer_att_dict=layer_att_dict,\n",
    "        target_edge=target_edge,\n",
    "        verbose=False,\n",
    "    )\n",
    "    # Get AVGATT scores\n",
    "    avgatt = get_AVGATT_edge(att=att, edge=target_edge)\n",
    "\n",
    "    return attattribute, attattribute_sim, avgatt\n",
    "\n",
    "def return_is_edge_list_Infection(edge_list, path_expl):\n",
    "    # Assuming path_expl is something like:\n",
    "    # [1215, 1024, 606, 10]. We need all edges in edge_list\n",
    "    # to be checked for the presence of this path.\n",
    "    expl_edge_set = {(path_expl[i], path_expl[i+1]) for i in range(len(path_expl) - 1)}\n",
    "\n",
    "    ground_truth_edge_list = []\n",
    "    for edge in edge_list:\n",
    "        if tuple(edge) in expl_edge_set:\n",
    "            ground_truth_edge_list.append(1)\n",
    "        else:\n",
    "            ground_truth_edge_list.append(0)\n",
    "    return ground_truth_edge_list\n",
    "\n",
    "def experiment_on_target_node(\n",
    "    target_idx: int, data, model, path_expl, self_loops=True, multiheads=False,\n",
    "):\n",
    "    num_hops = get_num_hops(model)\n",
    "    num_layers = num_hops\n",
    "\n",
    "    edge_lists = return_edges_in_k_hop(\n",
    "        data=data, target_idx=target_idx, hop=2, self_loops=self_loops\n",
    "    )\n",
    "    # 3. For all edges in the k-hop neighborhood, we get the attribution scores\n",
    "    # according to ATTATTRIBUTE, ATTATTRIBUTE_sim, and AVGATT.\n",
    "    # First, prepare ingredients for analysis\n",
    "\n",
    "    num_layers = get_num_hops(model)\n",
    "    if multiheads:\n",
    "        att_dict_raw = get_attention_raw_dict_multihead(model, data)\n",
    "    else:\n",
    "        att_dict_raw = get_attention_raw_dict(model, data)\n",
    "    att_dict = process_attention_dict(att_dict_raw)\n",
    "    comp_graph = get_computation_graph(\n",
    "        edge_index=data.edge_index, k=num_layers, target_idx=target_idx\n",
    "    )\n",
    "    (\n",
    "        nodes_per_level_original,\n",
    "        num_nodes_per_level,\n",
    "        true_node_label,\n",
    "    ) = get_nodes_per_level_from_comp_graph_full(comp_graph=comp_graph)\n",
    "    nodes_per_level_new = reindex_nodes_per_level(\n",
    "        nodes_per_level_original, num_nodes_per_level\n",
    "    )\n",
    "    comp_graph_new = translate_comp_graph(\n",
    "        comp_graph=comp_graph,\n",
    "        nodes_per_level_new=nodes_per_level_new,\n",
    "        nodes_per_level_original=nodes_per_level_original,\n",
    "    )\n",
    "    layer_att_dict = get_att_dict_per_layer(\n",
    "        comp_graph=comp_graph, comp_graph_new=comp_graph_new, att_dict=att_dict\n",
    "    )\n",
    "\n",
    "    # Get results for all edges in the k-hop neighborhood\n",
    "    attattribute_list, attattribute_sim_list, avgatt_list = [], [], []\n",
    "    # Get the attention weights again\n",
    "    with torch.no_grad():\n",
    "        model(data.x, data.edge_index, return_att=True)\n",
    "        att = model.att \n",
    "        att = average_attention_heads(att)\n",
    "        model.att = att\n",
    "\n",
    "    for current_edge in edge_lists:\n",
    "        attattribute, attattribute_sim, avgatt = get_edge_scores(\n",
    "            target_edge=tuple(current_edge),\n",
    "            comp_graph=comp_graph,\n",
    "            comp_graph_new=comp_graph_new,\n",
    "            layer_att_dict=layer_att_dict,\n",
    "            att=att,\n",
    "        )\n",
    "        attattribute_list.append(attattribute)\n",
    "        attattribute_sim_list.append(attattribute_sim)\n",
    "        avgatt_list.append(avgatt)\n",
    "\n",
    "    ground_truth_edge_list = return_is_edge_list_Infection(edge_lists, path_expl)\n",
    "\n",
    "    return (\n",
    "        attattribute_list,\n",
    "        attattribute_sim_list,\n",
    "        avgatt_list,\n",
    "        ground_truth_edge_list,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_on_target_node(\n",
    "    target_idx: int, data, model, path_expl, self_loops=True, multiheads=False,\n",
    "):\n",
    "    num_hops = get_num_hops(model)\n",
    "    num_layers = num_hops\n",
    "\n",
    "\n",
    "    # 3. For all edges in the k-hop neighborhood, we get the attribution scores\n",
    "    # according to ATTATTRIBUTE, ATTATTRIBUTE_sim, and AVGATT.\n",
    "    # First, prepare ingredients for analysis\n",
    "\n",
    "    num_layers = get_num_hops(model)\n",
    "    if multiheads:\n",
    "        att_dict_raw = get_attention_raw_dict_multihead(model, data)\n",
    "    else:\n",
    "        att_dict_raw = get_attention_raw_dict(model, data)\n",
    "    att_dict = process_attention_dict(att_dict_raw)\n",
    "    comp_graph = get_computation_graph(\n",
    "        edge_index=data.edge_index, k=num_layers, target_idx=target_idx\n",
    "    )\n",
    "    (\n",
    "        nodes_per_level_original,\n",
    "        num_nodes_per_level,\n",
    "        true_node_label,\n",
    "    ) = get_nodes_per_level_from_comp_graph_full(comp_graph=comp_graph)\n",
    "    nodes_per_level_new = reindex_nodes_per_level(\n",
    "        nodes_per_level_original, num_nodes_per_level\n",
    "    )\n",
    "    comp_graph_new = translate_comp_graph(\n",
    "        comp_graph=comp_graph,\n",
    "        nodes_per_level_new=nodes_per_level_new,\n",
    "        nodes_per_level_original=nodes_per_level_original,\n",
    "    )\n",
    "    layer_att_dict = get_att_dict_per_layer(\n",
    "        comp_graph=comp_graph, comp_graph_new=comp_graph_new, att_dict=att_dict\n",
    "    )\n",
    "\n",
    "    # Get results for all edges in the k-hop neighborhood\n",
    "    attattribute_list, attattribute_sim_list, avgatt_list = [], [], []\n",
    "    # Get the attention weights again\n",
    "    with torch.no_grad():\n",
    "        model(data.x, data.edge_index, return_att=True)\n",
    "        att = model.att \n",
    "        att = average_attention_heads(att)\n",
    "        model.att = att\n",
    "\n",
    "    for current_edge in edge_lists:\n",
    "        attattribute, attattribute_sim, avgatt = get_edge_scores(\n",
    "            target_edge=tuple(current_edge),\n",
    "            comp_graph=comp_graph,\n",
    "            comp_graph_new=comp_graph_new,\n",
    "            layer_att_dict=layer_att_dict,\n",
    "            att=att,\n",
    "        )\n",
    "        attattribute_list.append(attattribute)\n",
    "        attattribute_sim_list.append(attattribute_sim)\n",
    "        avgatt_list.append(avgatt)\n",
    "\n",
    "data = torch.load('/workspace/Datasets/Infection_50002d_sp.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "edge_lists = return_edges_in_k_hop(\n",
    "    data=data, target_idx=target_idx, hop=2, self_loops=True\n",
    ")\n",
    "\n",
    "ground_truth_edge_list = return_is_edge_list_Infection(edge_lists, path_expl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAT 2 layer 1 head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx, k_hop_subgraph, remove_self_loops, add_self_loops\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "dataset_name = 'Infection_50002d_sp'\n",
    "config = '2L1H'\n",
    "\n",
    "# Load the data\n",
    "data = torch.load(f'/workspace/Datasets/{dataset_name}.pt',map_location ='cpu')\n",
    "# Load the model\n",
    "results = torch.load(f'/workspace/Experimental_Artifacts/Faithfulness_GAT_infection_{config}_Attributions.pt',map_location ='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load experiments from local\n",
    "\n",
    "attattribute_list = results['attattribute']\n",
    "attattribute_sim_list = results['attattribute_sim']\n",
    "avgatt_list = results['avgatt']\n",
    "ground_truth_edge_list = torch.load(\n",
    "    f\"/workspace/Experimental_Results_old/Infection_50003d_sp_GAT_infection_3L1H_sp_ground_truth_edge_list_Accuracy_test.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [19171, 19738]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m random_attr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(ground_truth_edge_list\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      7\u001b[0m random_attr_roc_auc \u001b[38;5;241m=\u001b[39m roc_auc_score(ground_truth_edge_list, random_attr)\n\u001b[0;32m----> 8\u001b[0m attattribute_roc_auc \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth_edge_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattattribute_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m attattribute_sim_roc_auc \u001b[38;5;241m=\u001b[39m roc_auc_score(ground_truth_edge_list, attattribute_sim_list)\n\u001b[1;32m     10\u001b[0m avgatt_roc_auc \u001b[38;5;241m=\u001b[39m roc_auc_score(ground_truth_edge_list, avgatt_list)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:572\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    570\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n\u001b[1;32m    571\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m label_binarize(y_true, classes\u001b[38;5;241m=\u001b[39mlabels)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    581\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    582\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    585\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    586\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/metrics/_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m     78\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:344\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    342\u001b[0m     )\n\u001b[0;32m--> 344\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m auc(fpr, tpr)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:992\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mroc_curve\u001b[39m(\n\u001b[1;32m    905\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    906\u001b[0m ):\n\u001b[1;32m    907\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;124;03m    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 992\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:751\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[0;32m--> 751\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n\u001b[1;32m    753\u001b[0m y_score \u001b[38;5;241m=\u001b[39m column_or_1d(y_score)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [19171, 19738]"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kendalltau, spearmanr, pearsonr\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "ground_truth_edge_list = torch.Tensor(ground_truth_edge_list)\n",
    "# Also include a random baseline\n",
    "random_attr = torch.rand(ground_truth_edge_list.shape)\n",
    "random_attr_roc_auc = roc_auc_score(ground_truth_edge_list, random_attr)\n",
    "attattribute_roc_auc = roc_auc_score(ground_truth_edge_list, attattribute_list)\n",
    "attattribute_sim_roc_auc = roc_auc_score(ground_truth_edge_list, attattribute_sim_list)\n",
    "avgatt_roc_auc = roc_auc_score(ground_truth_edge_list, avgatt_list)\n",
    "\n",
    "# Print results\n",
    "print(\"ROC AUC for ATTATTRIBUTE / ATTATTRIBUTE_SIM / AVGATT / RANDOM\")\n",
    "print(f\"{attattribute_roc_auc:.4f}, {attattribute_sim_roc_auc:.4f}, {avgatt_roc_auc:.4f}, {random_attr_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAT 3 layer 2 head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx, k_hop_subgraph, remove_self_loops, add_self_loops\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "dataset_name = 'Infection_50003d_sp'\n",
    "model_name = f'GAT_infection_3L2H_sp'\n",
    "\n",
    "# Load the data\n",
    "data = torch.load(f'/workspace/{dataset_name}.pt',map_location ='cpu')\n",
    "# Load the model\n",
    "model = torch.load(f'/workspace/{model_name}.pt',map_location ='cpu')\n",
    "model.eval()\n",
    "# Get the attention weights\n",
    "with torch.no_grad():\n",
    "    out = model(data.x, data.edge_index, return_att=True)\n",
    "    att = model.att \n",
    "    # att = average_attention_heads(att)\n",
    "    # model.att = att\n",
    "\n",
    "# data.edge_index = add_self_loops(remove_self_loops(data.edge_index)[0])[0]\n",
    "# G = to_networkx(data, to_undirected=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "attattribute_list, attattribute_sim_list, avgatt_list = [], [], []\n",
    "ground_truth_edge_list = []\n",
    "\n",
    "for idx, target_node in enumerate(data.unique_solution_nodes):\n",
    "    path_expl = data.unique_solution_explanations[idx]\n",
    "    target_node_results = experiment_on_target_node(\n",
    "        target_idx=target_node,\n",
    "        data=data,\n",
    "        model=model,\n",
    "        path_expl=path_expl,\n",
    "        self_loops=True,\n",
    "        multiheads=True,\n",
    "    )\n",
    "    attattribute_list_curr = target_node_results[0]\n",
    "    attattribute_sim_list_curr = target_node_results[1]\n",
    "    avgatt_list_curr = target_node_results[2]\n",
    "    ground_truth_edge_list_curr = target_node_results[3]\n",
    "\n",
    "    attattribute_list.extend(attattribute_list_curr)\n",
    "    attattribute_sim_list.extend(attattribute_sim_list_curr)\n",
    "    avgatt_list.extend(avgatt_list_curr)\n",
    "    ground_truth_edge_list.extend(ground_truth_edge_list_curr)\n",
    "\n",
    "torch.save(\n",
    "    torch.Tensor(attattribute_list),\n",
    "    f\"/workspace/{dataset_name}_{model_name}_attattribute_list_Accuracy_test.pt\",\n",
    ")\n",
    "torch.save(\n",
    "    torch.Tensor(attattribute_sim_list),\n",
    "    f\"/workspace/{dataset_name}_{model_name}_attattribute_sim_list_Accuracy_test.pt\",\n",
    ")\n",
    "torch.save(\n",
    "    torch.Tensor(avgatt_list), f\"/workspace/{dataset_name}_{model_name}_avgatt_list_Accuracy_test.pt\"\n",
    ")\n",
    "torch.save(\n",
    "    torch.Tensor(ground_truth_edge_list),\n",
    "    f\"/workspace/{dataset_name}_{model_name}_ground_truth_edge_list_Accuracy_test.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load experiments from local\n",
    "\n",
    "attattribute_list = torch.load(\n",
    "    f\"/workspace/{dataset_name}_{model_name}_attattribute_list_Accuracy_test.pt\"\n",
    ")\n",
    "attattribute_sim_list = torch.load(\n",
    "    f\"/workspace/{dataset_name}_{model_name}_attattribute_sim_list_Accuracy_test.pt\"\n",
    ")\n",
    "avgatt_list = torch.load(f\"/workspace/{dataset_name}_{model_name}_avgatt_list_Accuracy_test.pt\")\n",
    "ground_truth_edge_list = torch.load(\n",
    "    f\"/workspace/{dataset_name}_{model_name}_ground_truth_edge_list_Accuracy_test.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau, spearmanr, pearsonr\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "ground_truth_edge_list = torch.Tensor(ground_truth_edge_list)\n",
    "# Also include a random baseline\n",
    "random_attr = torch.rand(ground_truth_edge_list.shape)\n",
    "random_attr_roc_auc = roc_auc_score(ground_truth_edge_list, random_attr)\n",
    "attattribute_roc_auc = roc_auc_score(ground_truth_edge_list, attattribute_list)\n",
    "attattribute_sim_roc_auc = roc_auc_score(ground_truth_edge_list, attattribute_sim_list)\n",
    "avgatt_roc_auc = roc_auc_score(ground_truth_edge_list, avgatt_list)\n",
    "\n",
    "# Print results\n",
    "# print(\"ROC AUC for ATTATTRIBUTE / ATTATTRIBUTE_SIM / AVGATT / RANDOM\")\n",
    "# print(f\"{attattribute_roc_auc:.4f}, {attattribute_sim_roc_auc:.4f}, {avgatt_roc_auc:.4f}, {random_attr_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAT 3 layer 4 head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx, k_hop_subgraph, remove_self_loops, add_self_loops\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "dataset_name = 'Infection_50003d_sp'\n",
    "model_name = f'GAT_infection_3L4H_sp'\n",
    "\n",
    "# Load the data\n",
    "data = torch.load(f'/workspace/{dataset_name}.pt',map_location ='cpu')\n",
    "# Load the model\n",
    "model = torch.load(f'/workspace/{model_name}.pt',map_location ='cpu')\n",
    "model.eval()\n",
    "# Get the attention weights\n",
    "with torch.no_grad():\n",
    "    out = model(data.x, data.edge_index, return_att=True)\n",
    "    att = model.att \n",
    "    # att = average_attention_heads(att)\n",
    "    # model.att = att\n",
    "\n",
    "# data.edge_index = add_self_loops(remove_self_loops(data.edge_index)[0])[0]\n",
    "# G = to_networkx(data, to_undirected=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "attattribute_list, attattribute_sim_list, avgatt_list = [], [], []\n",
    "ground_truth_edge_list = []\n",
    "\n",
    "for idx, target_node in enumerate(data.unique_solution_nodes):\n",
    "    path_expl = data.unique_solution_explanations[idx]\n",
    "    target_node_results = experiment_on_target_node(\n",
    "        target_idx=target_node,\n",
    "        data=data,\n",
    "        model=model,\n",
    "        path_expl=path_expl,\n",
    "        self_loops=True,\n",
    "        multiheads=True,\n",
    "    )\n",
    "    attattribute_list_curr = target_node_results[0]\n",
    "    attattribute_sim_list_curr = target_node_results[1]\n",
    "    avgatt_list_curr = target_node_results[2]\n",
    "    ground_truth_edge_list_curr = target_node_results[3]\n",
    "\n",
    "    attattribute_list.extend(attattribute_list_curr)\n",
    "    attattribute_sim_list.extend(attattribute_sim_list_curr)\n",
    "    avgatt_list.extend(avgatt_list_curr)\n",
    "    ground_truth_edge_list.extend(ground_truth_edge_list_curr)\n",
    "\n",
    "torch.save(\n",
    "    torch.Tensor(attattribute_list),\n",
    "    f\"/workspace/{dataset_name}_{model_name}_attattribute_list_Accuracy_test.pt\",\n",
    ")\n",
    "torch.save(\n",
    "    torch.Tensor(attattribute_sim_list),\n",
    "    f\"/workspace/{dataset_name}_{model_name}_attattribute_sim_list_Accuracy_test.pt\",\n",
    ")\n",
    "torch.save(\n",
    "    torch.Tensor(avgatt_list), f\"/workspace/{dataset_name}_{model_name}_avgatt_list_Accuracy_test.pt\"\n",
    ")\n",
    "torch.save(\n",
    "    torch.Tensor(ground_truth_edge_list),\n",
    "    f\"/workspace/{dataset_name}_{model_name}_ground_truth_edge_list_Accuracy_test.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load experiments from local\n",
    "\n",
    "attattribute_list = torch.load(\n",
    "    f\"/workspace/{dataset_name}_{model_name}_attattribute_list_Accuracy_test.pt\"\n",
    ")\n",
    "attattribute_sim_list = torch.load(\n",
    "    f\"/workspace/{dataset_name}_{model_name}_attattribute_sim_list_Accuracy_test.pt\"\n",
    ")\n",
    "avgatt_list = torch.load(f\"/workspace/{dataset_name}_{model_name}_avgatt_list_Accuracy_test.pt\")\n",
    "ground_truth_edge_list = torch.load(\n",
    "    f\"/workspace/{dataset_name}_{model_name}_ground_truth_edge_list_Accuracy_test.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau, spearmanr, pearsonr\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "ground_truth_edge_list = torch.Tensor(ground_truth_edge_list)\n",
    "# Also include a random baseline\n",
    "random_attr = torch.rand(ground_truth_edge_list.shape)\n",
    "random_attr_roc_auc = roc_auc_score(ground_truth_edge_list, random_attr)\n",
    "attattribute_roc_auc = roc_auc_score(ground_truth_edge_list, attattribute_list)\n",
    "attattribute_sim_roc_auc = roc_auc_score(ground_truth_edge_list, attattribute_sim_list)\n",
    "avgatt_roc_auc = roc_auc_score(ground_truth_edge_list, avgatt_list)\n",
    "\n",
    "# Print results\n",
    "# print(\"ROC AUC for ATTATTRIBUTE / ATTATTRIBUTE_SIM / AVGATT / RANDOM\")\n",
    "# print(f\"{attattribute_roc_auc:.4f}, {attattribute_sim_roc_auc:.4f}, {avgatt_roc_auc:.4f}, {random_attr_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAT 3 layer 8 head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx, k_hop_subgraph, remove_self_loops, add_self_loops\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "dataset_name = 'Infection_50003d_sp'\n",
    "model_name = f'GAT_infection_3L8H_sp'\n",
    "\n",
    "# Load the data\n",
    "data = torch.load(f'/workspace/{dataset_name}.pt',map_location ='cpu')\n",
    "# Load the model\n",
    "model = torch.load(f'/workspace/{model_name}.pt',map_location ='cpu')\n",
    "model.eval()\n",
    "# Get the attention weights\n",
    "with torch.no_grad():\n",
    "    out = model(data.x, data.edge_index, return_att=True)\n",
    "    att = model.att \n",
    "    # att = average_attention_heads(att)\n",
    "    # model.att = att\n",
    "\n",
    "# data.edge_index = add_self_loops(remove_self_loops(data.edge_index)[0])[0]\n",
    "# G = to_networkx(data, to_undirected=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "attattribute_list, attattribute_sim_list, avgatt_list = [], [], []\n",
    "ground_truth_edge_list = []\n",
    "\n",
    "for idx, target_node in enumerate(data.unique_solution_nodes):\n",
    "    path_expl = data.unique_solution_explanations[idx]\n",
    "    target_node_results = experiment_on_target_node(\n",
    "        target_idx=target_node,\n",
    "        data=data,\n",
    "        model=model,\n",
    "        path_expl=path_expl,\n",
    "        self_loops=True,\n",
    "        multiheads=True,\n",
    "    )\n",
    "    attattribute_list_curr = target_node_results[0]\n",
    "    attattribute_sim_list_curr = target_node_results[1]\n",
    "    avgatt_list_curr = target_node_results[2]\n",
    "    ground_truth_edge_list_curr = target_node_results[3]\n",
    "\n",
    "    attattribute_list.extend(attattribute_list_curr)\n",
    "    attattribute_sim_list.extend(attattribute_sim_list_curr)\n",
    "    avgatt_list.extend(avgatt_list_curr)\n",
    "    ground_truth_edge_list.extend(ground_truth_edge_list_curr)\n",
    "\n",
    "torch.save(\n",
    "    torch.Tensor(attattribute_list),\n",
    "    f\"/workspace/{dataset_name}_{model_name}_attattribute_list_Accuracy_test.pt\",\n",
    ")\n",
    "torch.save(\n",
    "    torch.Tensor(attattribute_sim_list),\n",
    "    f\"/workspace/{dataset_name}_{model_name}_attattribute_sim_list_Accuracy_test.pt\",\n",
    ")\n",
    "torch.save(\n",
    "    torch.Tensor(avgatt_list), f\"/workspace/{dataset_name}_{model_name}_avgatt_list_Accuracy_test.pt\"\n",
    ")\n",
    "torch.save(\n",
    "    torch.Tensor(ground_truth_edge_list),\n",
    "    f\"/workspace/{dataset_name}_{model_name}_ground_truth_edge_list_Accuracy_test.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load experiments from local\n",
    "\n",
    "attattribute_list = torch.load(\n",
    "    f\"/workspace/{dataset_name}_{model_name}_attattribute_list_Accuracy_test.pt\"\n",
    ")\n",
    "attattribute_sim_list = torch.load(\n",
    "    f\"/workspace/{dataset_name}_{model_name}_attattribute_sim_list_Accuracy_test.pt\"\n",
    ")\n",
    "avgatt_list = torch.load(f\"/workspace/{dataset_name}_{model_name}_avgatt_list_Accuracy_test.pt\")\n",
    "ground_truth_edge_list = torch.load(\n",
    "    f\"/workspace/{dataset_name}_{model_name}_ground_truth_edge_list_Accuracy_test.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC for ATTATTRIBUTE / ATTATTRIBUTE_SIM / AVGATT / RANDOM\n",
      "0.9305, 0.9471, 0.8927, 0.5043\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kendalltau, spearmanr, pearsonr\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "ground_truth_edge_list = torch.Tensor(ground_truth_edge_list)\n",
    "# Also include a random baseline\n",
    "random_attr = torch.rand(ground_truth_edge_list.shape)\n",
    "random_attr_roc_auc = roc_auc_score(ground_truth_edge_list, random_attr)\n",
    "attattribute_roc_auc = roc_auc_score(ground_truth_edge_list, attattribute_list)\n",
    "attattribute_sim_roc_auc = roc_auc_score(ground_truth_edge_list, attattribute_sim_list)\n",
    "avgatt_roc_auc = roc_auc_score(ground_truth_edge_list, avgatt_list)\n",
    "\n",
    "# Print results\n",
    "print(\"ROC AUC for ATTATTRIBUTE / ATTATTRIBUTE_SIM / AVGATT / RANDOM\")\n",
    "print(f\"{attattribute_roc_auc:.4f}, {attattribute_sim_roc_auc:.4f}, {avgatt_roc_auc:.4f}, {random_attr_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx, k_hop_subgraph, remove_self_loops, add_self_loops\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "dataset_name = 'Infection_50003d_sp'\n",
    "model_name = f'GAT_infection_3L1H_sp'\n",
    "\n",
    "# Load the data\n",
    "data = torch.load(f'/workspace/{dataset_name}.pt',map_location ='cpu')\n",
    "# Load the model\n",
    "model = torch.load(f'/workspace/{model_name}.pt',map_location ='cpu')\n",
    "model.eval()\n",
    "# Get the attention weights\n",
    "with torch.no_grad():\n",
    "    out = model(data.x, data.edge_index, return_att=True)\n",
    "    att = model.att \n",
    "    # att = average_attention_heads(att)\n",
    "    # model.att = att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_all_ground_truth_edges(unique_solution_explanations):\n",
    "    edge_mask = torch.zeros_like(data.edge_index[0], dtype=torch.bool)\n",
    "    all_ground_truth_edges = set()\n",
    "    for expl_path in data.unique_solution_explanations:\n",
    "        for curr_idx in range(len(expl_path)-1):\n",
    "            all_ground_truth_edges.add((expl_path[curr_idx], expl_path[curr_idx+1]))\n",
    "\n",
    "    for idx, curr_edge in enumerate(data.edge_index.t()):\n",
    "        if (curr_edge[0].item(), curr_edge[1].item()) in all_ground_truth_edges:\n",
    "            edge_mask[idx] = True\n",
    "\n",
    "    return edge_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.edge_mask = return_all_ground_truth_edges(data.unique_solution_explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=50),\n",
    "    explanation_type='phenomenon',\n",
    "    node_mask_type='object',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='raw',\n",
    "    ),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC (explanation type phenomenon): 0.4972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "# Explanation ROC AUC over all test nodes:\n",
    "targets, preds = [], []\n",
    "node_indices = range(300, 700)\n",
    "for node_index in tqdm(node_indices, leave=False, desc='Train Explainer'):\n",
    "    target = data.y\n",
    "    explanation = explainer(data.x, data.edge_index, index=node_index,\n",
    "                            target=target)\n",
    "\n",
    "    _, _, _, hard_edge_mask = k_hop_subgraph(node_index, num_hops=3,\n",
    "                                            edge_index=data.edge_index)\n",
    "\n",
    "    targets.append(data.edge_mask[hard_edge_mask].cpu())\n",
    "    preds.append(explanation.edge_mask[hard_edge_mask].cpu())\n",
    "\n",
    "auc = roc_auc_score(torch.cat(targets), torch.cat(preds))\n",
    "print(f'Mean ROC AUC (explanation type phenomenon): {auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4971986745517879"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC (explanation type phenomenon): 0.7198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch_geometric.explain import Explainer, PGExplainer\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=PGExplainer(epochs=30, lr=0.003),\n",
    "    explanation_type='phenomenon',\n",
    "    # node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='raw',\n",
    "    ),\n",
    ")\n",
    "\n",
    "for epoch in range(30):\n",
    "    for index in range(300, 700):  # Indices to train against.\n",
    "        loss = explainer.algorithm.train(epoch, model, data.x, data.edge_index,\n",
    "                                        target=target, index=index)\n",
    "        \n",
    "# Explanation ROC AUC over all test nodes:\n",
    "targets, preds = [], []\n",
    "node_indices = range(300, 700)\n",
    "for node_index in tqdm(node_indices, leave=False, desc='Train Explainer'):\n",
    "    target = data.y\n",
    "    explanation = explainer(data.x, data.edge_index, index=node_index,\n",
    "                            target=target)\n",
    "\n",
    "    _, _, _, hard_edge_mask = k_hop_subgraph(node_index, num_hops=3,\n",
    "                                            edge_index=data.edge_index)\n",
    "\n",
    "    targets.append(data.edge_mask[hard_edge_mask].cpu())\n",
    "    preds.append(explanation.edge_mask[hard_edge_mask].cpu())\n",
    "\n",
    "auc_pgexpl = roc_auc_score(torch.cat(targets), torch.cat(preds))\n",
    "print(f'Mean ROC AUC (explanation type phenomenon): {auc_pgexpl:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7197579851612776"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_pgexpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
