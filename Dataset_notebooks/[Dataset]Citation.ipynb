{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GAT models for Cora, Citeseer and Pubmed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train(model, optimizer, data, epochs):\n",
    "    model.train()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        acc = (out[data.train_mask].argmax(dim=1) == data.y[data.train_mask]).sum().item() / data.train_mask.sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model, loss, acc\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    x, edge_index, y = data.x, data.edge_index, data.y\n",
    "    out = model(x, edge_index)\n",
    "    loss = criterion(out[data.test_mask], y[data.test_mask])\n",
    "    acc = (out[data.test_mask].argmax(dim=1) == y[data.test_mask]).sum().item() / data.test_mask.sum().item()\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. nodes: 2708 | Num. edges: 10556 | Num. classes: 7 | Num. features: 1433 | Num. train.: 700 | Num. test: 2008\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = 'Cora'\n",
    "transform_lcc = T.Compose([T.LargestConnectedComponents()])\n",
    "transform = T.Compose([T.NormalizeFeatures(),\n",
    "                    T.RandomNodeSplit(split='test_rest', \n",
    "                                    num_train_per_class=100,\n",
    "                                    num_val=0)])\n",
    "path = osp.join(osp.dirname(osp.realpath('/workspace/[Dataset]Citation.ipynb')), '..', 'data', dataset)\n",
    "dataset_temp = Planetoid(path, dataset, transform=transform_lcc)\n",
    "data_temp = dataset_temp[0].to(device)\n",
    "dataset = Planetoid(path, dataset, transform=transform)\n",
    "# Print some dataset statistics\n",
    "print(f\"Num. nodes: {data.num_nodes} | Num. edges: {data.num_edges} | Num. classes: {data.y.max() + 1} | Num. features: {data.num_features} | Num. train.: {data.train_mask.sum()} | Num. test: {data.test_mask.sum()}\")\n",
    "# Save to local\n",
    "torch.save(data, \"/workspace/Cora.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GAT_Cora_2L1H, Loss: 1.7192, Train Accuracy: 0.9057, Test Loss: 1.7484, Test Accuracy: 0.8327\n",
      "Model: GAT_Cora_2L2H, Loss: 1.6044, Train Accuracy: 0.9029, Test Loss: 1.6541, Test Accuracy: 0.8327\n",
      "Model: GAT_Cora_2L4H, Loss: 1.3822, Train Accuracy: 0.9100, Test Loss: 1.4581, Test Accuracy: 0.8416\n",
      "Model: GAT_Cora_2L8H, Loss: 1.0693, Train Accuracy: 0.9000, Test Loss: 1.1965, Test Accuracy: 0.8416\n",
      "Model: GAT_Cora_3L1H, Loss: 1.3797, Train Accuracy: 0.8800, Test Loss: 1.4372, Test Accuracy: 0.8098\n",
      "Model: GAT_Cora_3L2H, Loss: 0.8098, Train Accuracy: 0.8957, Test Loss: 0.9117, Test Accuracy: 0.8342\n",
      "Model: GAT_Cora_3L4H, Loss: 0.3302, Train Accuracy: 0.9243, Test Loss: 0.5271, Test Accuracy: 0.8466\n",
      "Model: GAT_Cora_3L8H, Loss: 0.1487, Train Accuracy: 0.9571, Test Loss: 0.5025, Test Accuracy: 0.8476\n"
     ]
    }
   ],
   "source": [
    "# Train GAT models on the BA-Shapes dataset\n",
    "from models import GAT_L2_intervention, GAT_L3_intervention\n",
    "\n",
    "out_channels = data.y.max().item() + 1\n",
    "\n",
    "# Define several GAT models with 1, 2, 4, 8 attention heads to be used for 'data.pt', and move them to the GPU device (if available)\n",
    "model1_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=1)\n",
    "model2_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=2)\n",
    "model4_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=4)\n",
    "model8_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=8)\n",
    "model1_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=1)\n",
    "model2_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=2)\n",
    "model4_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=4)\n",
    "model8_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=8)\n",
    "\n",
    "# Move the models to the GPU device (if available)\n",
    "model1_L2 = model1_L2.to(device)\n",
    "model2_L2 = model2_L2.to(device)\n",
    "model4_L2 = model4_L2.to(device)\n",
    "model8_L2 = model8_L2.to(device)\n",
    "model1_L3 = model1_L3.to(device)\n",
    "model2_L3 = model2_L3.to(device)\n",
    "model4_L3 = model4_L3.to(device)\n",
    "model8_L3 = model8_L3.to(device)\n",
    "\n",
    "\"\"\"\n",
    "Now we can train all the models and compare their performance.\n",
    "Keep the number of epochs and the learning rate the same for all the models.\n",
    "\"\"\"\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = 60\n",
    "# Define the learning rate\n",
    "lr = 0.001\n",
    "# Prepare the optimizer\n",
    "optimizer1_L2 = torch.optim.Adam(model1_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer2_L2 = torch.optim.Adam(model2_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer4_L2 = torch.optim.Adam(model4_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer8_L2 = torch.optim.Adam(model8_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer1_L3 = torch.optim.Adam(model1_L3.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer2_L3 = torch.optim.Adam(model2_L3.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer4_L3 = torch.optim.Adam(model4_L3.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer8_L3 = torch.optim.Adam(model8_L3.parameters(), lr=lr, weight_decay=0)\n",
    "\n",
    "# Train the models\n",
    "model1_L2, loss1_L2, acc1_L2 = train(model=model1_L2, data=data, optimizer=optimizer1_L2, epochs=epochs)\n",
    "model2_L2, loss2_L2, acc2_L2 = train(model=model2_L2, data=data, optimizer=optimizer2_L2, epochs=epochs)\n",
    "model4_L2, loss4_L2, acc4_L2 = train(model=model4_L2, data=data, optimizer=optimizer4_L2, epochs=epochs)\n",
    "model8_L2, loss8_L2, acc8_L2 = train(model=model8_L2, data=data, optimizer=optimizer8_L2, epochs=epochs)\n",
    "model1_L3, loss1_L3, acc1_L3 = train(model=model1_L3, data=data, optimizer=optimizer1_L3, epochs=epochs)\n",
    "model2_L3, loss2_L3, acc2_L3 = train(model=model2_L3, data=data, optimizer=optimizer2_L3, epochs=epochs)\n",
    "model4_L3, loss4_L3, acc4_L3 = train(model=model4_L3, data=data, optimizer=optimizer4_L3, epochs=epochs)\n",
    "model8_L3, loss8_L3, acc8_L3 = train(model=model8_L3, data=data, optimizer=optimizer8_L3, epochs=epochs)\n",
    "\n",
    "# Test the models\n",
    "test_loss1_L2, test_acc1_L2 = test(model=model1_L2, data=data)\n",
    "test_loss2_L2, test_acc2_L2 = test(model=model2_L2, data=data)\n",
    "test_loss4_L2, test_acc4_L2 = test(model=model4_L2, data=data)\n",
    "test_loss8_L2, test_acc8_L2 = test(model=model8_L2, data=data)\n",
    "test_loss1_L3, test_acc1_L3 = test(model=model1_L3, data=data)\n",
    "test_loss2_L3, test_acc2_L3 = test(model=model2_L3, data=data)\n",
    "test_loss4_L3, test_acc4_L3 = test(model=model4_L3, data=data)\n",
    "test_loss8_L3, test_acc8_L3 = test(model=model8_L3, data=data)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Model: GAT_Cora_2L1H, Loss: {loss1_L2:.4f}, Train Accuracy: {acc1_L2:.4f}, Test Loss: {test_loss1_L2:.4f}, Test Accuracy: {test_acc1_L2:.4f}\")\n",
    "print(f\"Model: GAT_Cora_2L2H, Loss: {loss2_L2:.4f}, Train Accuracy: {acc2_L2:.4f}, Test Loss: {test_loss2_L2:.4f}, Test Accuracy: {test_acc2_L2:.4f}\")\n",
    "print(f\"Model: GAT_Cora_2L4H, Loss: {loss4_L2:.4f}, Train Accuracy: {acc4_L2:.4f}, Test Loss: {test_loss4_L2:.4f}, Test Accuracy: {test_acc4_L2:.4f}\")\n",
    "print(f\"Model: GAT_Cora_2L8H, Loss: {loss8_L2:.4f}, Train Accuracy: {acc8_L2:.4f}, Test Loss: {test_loss8_L2:.4f}, Test Accuracy: {test_acc8_L2:.4f}\")\n",
    "print(f\"Model: GAT_Cora_3L1H, Loss: {loss1_L3:.4f}, Train Accuracy: {acc1_L3:.4f}, Test Loss: {test_loss1_L3:.4f}, Test Accuracy: {test_acc1_L3:.4f}\")\n",
    "print(f\"Model: GAT_Cora_3L2H, Loss: {loss2_L3:.4f}, Train Accuracy: {acc2_L3:.4f}, Test Loss: {test_loss2_L3:.4f}, Test Accuracy: {test_acc2_L3:.4f}\")\n",
    "print(f\"Model: GAT_Cora_3L4H, Loss: {loss4_L3:.4f}, Train Accuracy: {acc4_L3:.4f}, Test Loss: {test_loss4_L3:.4f}, Test Accuracy: {test_acc4_L3:.4f}\")\n",
    "print(f\"Model: GAT_Cora_3L8H, Loss: {loss8_L3:.4f}, Train Accuracy: {acc8_L3:.4f}, Test Loss: {test_loss8_L3:.4f}, Test Accuracy: {test_acc8_L3:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model locally\n",
    "torch.save(model1_L2, '/workspace/GAT_Cora_2L1H.pt')\n",
    "torch.save(model2_L2, '/workspace/GAT_Cora_2L2H.pt')\n",
    "torch.save(model4_L2, '/workspace/GAT_Cora_2L4H.pt')\n",
    "torch.save(model8_L2, '/workspace/GAT_Cora_2L8H.pt')\n",
    "\n",
    "torch.save(model1_L3, '/workspace/GAT_Cora_3L1H.pt')\n",
    "torch.save(model2_L3, '/workspace/GAT_Cora_3L2H.pt')\n",
    "torch.save(model4_L3, '/workspace/GAT_Cora_3L4H.pt')\n",
    "torch.save(model8_L3, '/workspace/GAT_Cora_3L8H.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citeseer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. nodes: 3327 | Num. edges: 9104 | Num. classes: 6 | Num. features: 3703 | Num. train.: 600 | Num. test: 2727\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = 'CiteSeer'\n",
    "transform = T.Compose([T.NormalizeFeatures(),\n",
    "                    T.RandomNodeSplit(split='test_rest', \n",
    "                                    num_train_per_class=100,\n",
    "                                    num_val=0)])\n",
    "path = osp.join(osp.dirname(osp.realpath('/workspace/[Dataset]Citation.ipynb')), '..', 'data', dataset)\n",
    "dataset = Planetoid(path, dataset, transform=transform)\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Print some dataset statistics\n",
    "print(f\"Num. nodes: {data.num_nodes} | Num. edges: {data.num_edges} | Num. classes: {data.y.max() + 1} | Num. features: {data.num_features} | Num. train.: {data.train_mask.sum()} | Num. test: {data.test_mask.sum()}\")\n",
    "# Save to local\n",
    "torch.save(data, \"/workspace/Citeseer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GAT_Citeseer_2L1H, Loss: 1.3092, Train Accuracy: 0.8817, Test Loss: 1.4677, Test Accuracy: 0.7334\n",
      "Model: GAT_Citeseer_2L2H, Loss: 1.0237, Train Accuracy: 0.8883, Test Loss: 1.2675, Test Accuracy: 0.7294\n",
      "Model: GAT_Citeseer_2L4H, Loss: 0.6952, Train Accuracy: 0.8983, Test Loss: 1.0480, Test Accuracy: 0.7319\n",
      "Model: GAT_Citeseer_2L8H, Loss: 0.3951, Train Accuracy: 0.9250, Test Loss: 0.8965, Test Accuracy: 0.7261\n",
      "Model: GAT_Citeseer_3L1H, Loss: 0.5238, Train Accuracy: 0.8783, Test Loss: 0.9247, Test Accuracy: 0.7173\n",
      "Model: GAT_Citeseer_3L2H, Loss: 0.2218, Train Accuracy: 0.9350, Test Loss: 0.9078, Test Accuracy: 0.7140\n",
      "Model: GAT_Citeseer_3L4H, Loss: 0.0866, Train Accuracy: 0.9783, Test Loss: 1.1514, Test Accuracy: 0.6799\n",
      "Model: GAT_Citeseer_3L8H, Loss: 0.0330, Train Accuracy: 0.9933, Test Loss: 1.5214, Test Accuracy: 0.6733\n"
     ]
    }
   ],
   "source": [
    "# Train GAT models on the BA-Shapes dataset\n",
    "from models import GAT_L2_intervention, GAT_L3_intervention\n",
    "\n",
    "out_channels = data.y.max().item() + 1\n",
    "\n",
    "# Define several GAT models with 1, 2, 4, 8 attention heads to be used for 'data.pt', and move them to the GPU device (if available)\n",
    "model1_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=1)\n",
    "model2_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=2)\n",
    "model4_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=4)\n",
    "model8_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=8)\n",
    "model1_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=1)\n",
    "model2_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=2)\n",
    "model4_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=4)\n",
    "model8_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=8)\n",
    "\n",
    "# Move the models to the GPU device (if available)\n",
    "model1_L2 = model1_L2.to(device)\n",
    "model2_L2 = model2_L2.to(device)\n",
    "model4_L2 = model4_L2.to(device)\n",
    "model8_L2 = model8_L2.to(device)\n",
    "model1_L3 = model1_L3.to(device)\n",
    "model2_L3 = model2_L3.to(device)\n",
    "model4_L3 = model4_L3.to(device)\n",
    "model8_L3 = model8_L3.to(device)\n",
    "\n",
    "\"\"\"\n",
    "Now we can train all the models and compare their performance.\n",
    "Keep the number of epochs and the learning rate the same for all the models.\n",
    "\"\"\"\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = 100\n",
    "# Define the learning rate\n",
    "lr = 0.001\n",
    "# Prepare the optimizer\n",
    "optimizer1_L2 = torch.optim.Adam(model1_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer2_L2 = torch.optim.Adam(model2_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer4_L2 = torch.optim.Adam(model4_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer8_L2 = torch.optim.Adam(model8_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer1_L3 = torch.optim.Adam(model1_L3.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer2_L3 = torch.optim.Adam(model2_L3.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer4_L3 = torch.optim.Adam(model4_L3.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer8_L3 = torch.optim.Adam(model8_L3.parameters(), lr=lr, weight_decay=0)\n",
    "\n",
    "# Train the models\n",
    "model1_L2, loss1_L2, acc1_L2 = train(model=model1_L2, data=data, optimizer=optimizer1_L2, epochs=epochs)\n",
    "model2_L2, loss2_L2, acc2_L2 = train(model=model2_L2, data=data, optimizer=optimizer2_L2, epochs=epochs)\n",
    "model4_L2, loss4_L2, acc4_L2 = train(model=model4_L2, data=data, optimizer=optimizer4_L2, epochs=epochs)\n",
    "model8_L2, loss8_L2, acc8_L2 = train(model=model8_L2, data=data, optimizer=optimizer8_L2, epochs=epochs)\n",
    "model1_L3, loss1_L3, acc1_L3 = train(model=model1_L3, data=data, optimizer=optimizer1_L3, epochs=epochs)\n",
    "model2_L3, loss2_L3, acc2_L3 = train(model=model2_L3, data=data, optimizer=optimizer2_L3, epochs=epochs)\n",
    "model4_L3, loss4_L3, acc4_L3 = train(model=model4_L3, data=data, optimizer=optimizer4_L3, epochs=epochs)\n",
    "model8_L3, loss8_L3, acc8_L3 = train(model=model8_L3, data=data, optimizer=optimizer8_L3, epochs=epochs)\n",
    "\n",
    "# Test the models\n",
    "test_loss1_L2, test_acc1_L2 = test(model=model1_L2, data=data)\n",
    "test_loss2_L2, test_acc2_L2 = test(model=model2_L2, data=data)\n",
    "test_loss4_L2, test_acc4_L2 = test(model=model4_L2, data=data)\n",
    "test_loss8_L2, test_acc8_L2 = test(model=model8_L2, data=data)\n",
    "test_loss1_L3, test_acc1_L3 = test(model=model1_L3, data=data)\n",
    "test_loss2_L3, test_acc2_L3 = test(model=model2_L3, data=data)\n",
    "test_loss4_L3, test_acc4_L3 = test(model=model4_L3, data=data)\n",
    "test_loss8_L3, test_acc8_L3 = test(model=model8_L3, data=data)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Model: GAT_Citeseer_2L1H, Loss: {loss1_L2:.4f}, Train Accuracy: {acc1_L2:.4f}, Test Loss: {test_loss1_L2:.4f}, Test Accuracy: {test_acc1_L2:.4f}\")\n",
    "print(f\"Model: GAT_Citeseer_2L2H, Loss: {loss2_L2:.4f}, Train Accuracy: {acc2_L2:.4f}, Test Loss: {test_loss2_L2:.4f}, Test Accuracy: {test_acc2_L2:.4f}\")\n",
    "print(f\"Model: GAT_Citeseer_2L4H, Loss: {loss4_L2:.4f}, Train Accuracy: {acc4_L2:.4f}, Test Loss: {test_loss4_L2:.4f}, Test Accuracy: {test_acc4_L2:.4f}\")\n",
    "print(f\"Model: GAT_Citeseer_2L8H, Loss: {loss8_L2:.4f}, Train Accuracy: {acc8_L2:.4f}, Test Loss: {test_loss8_L2:.4f}, Test Accuracy: {test_acc8_L2:.4f}\")\n",
    "print(f\"Model: GAT_Citeseer_3L1H, Loss: {loss1_L3:.4f}, Train Accuracy: {acc1_L3:.4f}, Test Loss: {test_loss1_L3:.4f}, Test Accuracy: {test_acc1_L3:.4f}\")\n",
    "print(f\"Model: GAT_Citeseer_3L2H, Loss: {loss2_L3:.4f}, Train Accuracy: {acc2_L3:.4f}, Test Loss: {test_loss2_L3:.4f}, Test Accuracy: {test_acc2_L3:.4f}\")\n",
    "print(f\"Model: GAT_Citeseer_3L4H, Loss: {loss4_L3:.4f}, Train Accuracy: {acc4_L3:.4f}, Test Loss: {test_loss4_L3:.4f}, Test Accuracy: {test_acc4_L3:.4f}\")\n",
    "print(f\"Model: GAT_Citeseer_3L8H, Loss: {loss8_L3:.4f}, Train Accuracy: {acc8_L3:.4f}, Test Loss: {test_loss8_L3:.4f}, Test Accuracy: {test_acc8_L3:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model locally\n",
    "torch.save(model1_L2, '/workspace/GAT_Citeseer_2L1H.pt')\n",
    "torch.save(model2_L2, '/workspace/GAT_Citeseer_2L2H.pt')\n",
    "torch.save(model4_L2, '/workspace/GAT_Citeseer_2L4H.pt')\n",
    "torch.save(model8_L2, '/workspace/GAT_Citeseer_2L8H.pt')\n",
    "\n",
    "torch.save(model1_L3, '/workspace/GAT_Citeseer_3L1H.pt')\n",
    "torch.save(model2_L3, '/workspace/GAT_Citeseer_3L2H.pt')\n",
    "torch.save(model4_L3, '/workspace/GAT_Citeseer_3L4H.pt')\n",
    "torch.save(model8_L3, '/workspace/GAT_Citeseer_3L8H.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. nodes: 19717 | Num. edges: 88648 | Num. classes: 3 | Num. features: 500 | Num. train.: 300 | Num. test: 19417\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = 'PubMed'\n",
    "transform = T.Compose([T.NormalizeFeatures(),\n",
    "                    T.RandomNodeSplit(split='test_rest', \n",
    "                                    num_train_per_class=100,\n",
    "                                    num_val=0)])\n",
    "path = osp.join(osp.dirname(osp.realpath('/workspace/[Dataset]Citation.ipynb')), '..', 'data', dataset)\n",
    "dataset = Planetoid(path, dataset, transform=transform)\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Print some dataset statistics\n",
    "print(f\"Num. nodes: {data.num_nodes} | Num. edges: {data.num_edges} | Num. classes: {data.y.max() + 1} | Num. features: {data.num_features} | Num. train.: {data.train_mask.sum()} | Num. test: {data.test_mask.sum()}\")\n",
    "# Save to local\n",
    "torch.save(data, \"/workspace/Pubmed.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GAT_Pubmed_2L1H, Loss: 0.7602, Train Accuracy: 0.8100, Test Loss: 0.8184, Test Accuracy: 0.7316\n",
      "Model: GAT_Pubmed_2L2H, Loss: 0.5968, Train Accuracy: 0.8333, Test Loss: 0.6898, Test Accuracy: 0.7536\n",
      "Model: GAT_Pubmed_2L4H, Loss: 0.4766, Train Accuracy: 0.8500, Test Loss: 0.5984, Test Accuracy: 0.7695\n",
      "Model: GAT_Pubmed_2L8H, Loss: 0.3535, Train Accuracy: 0.8933, Test Loss: 0.5215, Test Accuracy: 0.7948\n",
      "Model: GAT_Pubmed_3L1H, Loss: 0.3548, Train Accuracy: 0.8900, Test Loss: 0.5218, Test Accuracy: 0.7921\n",
      "Model: GAT_Pubmed_3L2H, Loss: 0.2183, Train Accuracy: 0.9300, Test Loss: 0.5265, Test Accuracy: 0.7970\n",
      "Model: GAT_Pubmed_3L4H, Loss: 0.0702, Train Accuracy: 0.9800, Test Loss: 0.7013, Test Accuracy: 0.7751\n",
      "Model: GAT_Pubmed_3L8H, Loss: 0.0224, Train Accuracy: 0.9967, Test Loss: 1.1359, Test Accuracy: 0.7474\n"
     ]
    }
   ],
   "source": [
    "# Train GAT models on the BA-Shapes dataset\n",
    "from models import GAT_L2_intervention, GAT_L3_intervention\n",
    "\n",
    "out_channels = data.y.max().item() + 1\n",
    "\n",
    "# Define several GAT models with 1, 2, 4, 8 attention heads to be used for 'data.pt', and move them to the GPU device (if available)\n",
    "model1_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=1)\n",
    "model2_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=2)\n",
    "model4_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=4)\n",
    "model8_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=8)\n",
    "model1_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=1)\n",
    "model2_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=2)\n",
    "model4_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=4)\n",
    "model8_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=8)\n",
    "\n",
    "# Move the models to the GPU device (if available)\n",
    "model1_L2 = model1_L2.to(device)\n",
    "model2_L2 = model2_L2.to(device)\n",
    "model4_L2 = model4_L2.to(device)\n",
    "model8_L2 = model8_L2.to(device)\n",
    "model1_L3 = model1_L3.to(device)\n",
    "model2_L3 = model2_L3.to(device)\n",
    "model4_L3 = model4_L3.to(device)\n",
    "model8_L3 = model8_L3.to(device)\n",
    "\n",
    "\"\"\"\n",
    "Now we can train all the models and compare their performance.\n",
    "Keep the number of epochs and the learning rate the same for all the models.\n",
    "\"\"\"\n",
    "# Define the number of epochs\n",
    "epochs = 100\n",
    "# Define the learning rate\n",
    "lr = 0.001\n",
    "# Prepare the optimizer\n",
    "optimizer1_L2 = torch.optim.Adam(model1_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer2_L2 = torch.optim.Adam(model2_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer4_L2 = torch.optim.Adam(model4_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer8_L2 = torch.optim.Adam(model8_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer1_L3 = torch.optim.Adam(model1_L3.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer2_L3 = torch.optim.Adam(model2_L3.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer4_L3 = torch.optim.Adam(model4_L3.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer8_L3 = torch.optim.Adam(model8_L3.parameters(), lr=lr, weight_decay=0)\n",
    "\n",
    "# Train the models\n",
    "model1_L2, loss1_L2, acc1_L2 = train(model=model1_L2, data=data, optimizer=optimizer1_L2, epochs=epochs)\n",
    "model2_L2, loss2_L2, acc2_L2 = train(model=model2_L2, data=data, optimizer=optimizer2_L2, epochs=epochs)\n",
    "model4_L2, loss4_L2, acc4_L2 = train(model=model4_L2, data=data, optimizer=optimizer4_L2, epochs=epochs)\n",
    "model8_L2, loss8_L2, acc8_L2 = train(model=model8_L2, data=data, optimizer=optimizer8_L2, epochs=epochs)\n",
    "model1_L3, loss1_L3, acc1_L3 = train(model=model1_L3, data=data, optimizer=optimizer1_L3, epochs=epochs)\n",
    "model2_L3, loss2_L3, acc2_L3 = train(model=model2_L3, data=data, optimizer=optimizer2_L3, epochs=epochs)\n",
    "model4_L3, loss4_L3, acc4_L3 = train(model=model4_L3, data=data, optimizer=optimizer4_L3, epochs=epochs)\n",
    "model8_L3, loss8_L3, acc8_L3 = train(model=model8_L3, data=data, optimizer=optimizer8_L3, epochs=epochs)\n",
    "\n",
    "# Test the models\n",
    "test_loss1_L2, test_acc1_L2 = test(model=model1_L2, data=data)\n",
    "test_loss2_L2, test_acc2_L2 = test(model=model2_L2, data=data)\n",
    "test_loss4_L2, test_acc4_L2 = test(model=model4_L2, data=data)\n",
    "test_loss8_L2, test_acc8_L2 = test(model=model8_L2, data=data)\n",
    "test_loss1_L3, test_acc1_L3 = test(model=model1_L3, data=data)\n",
    "test_loss2_L3, test_acc2_L3 = test(model=model2_L3, data=data)\n",
    "test_loss4_L3, test_acc4_L3 = test(model=model4_L3, data=data)\n",
    "test_loss8_L3, test_acc8_L3 = test(model=model8_L3, data=data)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Model: GAT_Pubmed_2L1H, Loss: {loss1_L2:.4f}, Train Accuracy: {acc1_L2:.4f}, Test Loss: {test_loss1_L2:.4f}, Test Accuracy: {test_acc1_L2:.4f}\")\n",
    "print(f\"Model: GAT_Pubmed_2L2H, Loss: {loss2_L2:.4f}, Train Accuracy: {acc2_L2:.4f}, Test Loss: {test_loss2_L2:.4f}, Test Accuracy: {test_acc2_L2:.4f}\")\n",
    "print(f\"Model: GAT_Pubmed_2L4H, Loss: {loss4_L2:.4f}, Train Accuracy: {acc4_L2:.4f}, Test Loss: {test_loss4_L2:.4f}, Test Accuracy: {test_acc4_L2:.4f}\")\n",
    "print(f\"Model: GAT_Pubmed_2L8H, Loss: {loss8_L2:.4f}, Train Accuracy: {acc8_L2:.4f}, Test Loss: {test_loss8_L2:.4f}, Test Accuracy: {test_acc8_L2:.4f}\")\n",
    "print(f\"Model: GAT_Pubmed_3L1H, Loss: {loss1_L3:.4f}, Train Accuracy: {acc1_L3:.4f}, Test Loss: {test_loss1_L3:.4f}, Test Accuracy: {test_acc1_L3:.4f}\")\n",
    "print(f\"Model: GAT_Pubmed_3L2H, Loss: {loss2_L3:.4f}, Train Accuracy: {acc2_L3:.4f}, Test Loss: {test_loss2_L3:.4f}, Test Accuracy: {test_acc2_L3:.4f}\")\n",
    "print(f\"Model: GAT_Pubmed_3L4H, Loss: {loss4_L3:.4f}, Train Accuracy: {acc4_L3:.4f}, Test Loss: {test_loss4_L3:.4f}, Test Accuracy: {test_acc4_L3:.4f}\")\n",
    "print(f\"Model: GAT_Pubmed_3L8H, Loss: {loss8_L3:.4f}, Train Accuracy: {acc8_L3:.4f}, Test Loss: {test_loss8_L3:.4f}, Test Accuracy: {test_acc8_L3:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model locally\n",
    "torch.save(model1_L2, '/workspace/GAT_Pubmed_2L1H.pt')\n",
    "torch.save(model2_L2, '/workspace/GAT_Pubmed_2L2H.pt')\n",
    "torch.save(model4_L2, '/workspace/GAT_Pubmed_2L4H.pt')\n",
    "torch.save(model8_L2, '/workspace/GAT_Pubmed_2L8H.pt')\n",
    "\n",
    "torch.save(model1_L3, '/workspace/GAT_Pubmed_3L1H.pt')\n",
    "torch.save(model2_L3, '/workspace/GAT_Pubmed_3L2H.pt')\n",
    "torch.save(model4_L3, '/workspace/GAT_Pubmed_3L4H.pt')\n",
    "torch.save(model8_L3, '/workspace/GAT_Pubmed_3L8H.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
