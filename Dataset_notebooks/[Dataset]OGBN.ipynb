{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GAT models for OGBN datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train(model, optimizer, data, epochs):\n",
    "    model.train()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index.to(device))\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        acc = (out[data.train_mask].argmax(dim=1) == data.y[data.train_mask]).sum().item() / data.train_mask.sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model, loss, acc\n",
    "\n",
    "def train_batch(model, optimizer, train_loader, epochs):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = total_correct = 0\n",
    "    for _ in range(epochs):\n",
    "        for batch_size, n_id, adjs in train_loader:\n",
    "            # `adjs` holds a list of `(edge_index, e_id, size)` tuples.\n",
    "            adjs = [adj.to(device) for adj in adjs]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x[n_id], adjs)\n",
    "            loss = F.nll_loss(out, y[n_id[:batch_size]])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += float(loss)\n",
    "            total_correct += int(out.argmax(dim=-1).eq(y[n_id[:batch_size]]).sum())\n",
    "\n",
    "    loss = total_loss / len(train_loader)\n",
    "    approx_acc = total_correct / train_idx.size(0)\n",
    "\n",
    "    return model, loss, approx_acc\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    x, edge_index, y = data.x, data.edge_index, data.y\n",
    "    out = model(x, edge_index)\n",
    "    loss = criterion(out[data.test_mask], y[data.test_mask])\n",
    "    acc = (out[data.test_mask].argmax(dim=1) == y[data.test_mask]).sum().item() / data.test_mask.sum().item()\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBGN-products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from ogb.nodeproppred import Evaluator, PygNodePropPredDataset\n",
    "\n",
    "from torch_geometric.loader import NeighborSampler\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "root = osp.join(osp.dirname(osp.realpath('[Dataset]OGBN.ipynb')), '..', 'data', 'products')\n",
    "dataset = PygNodePropPredDataset('ogbn-products', root)\n",
    "split_idx = dataset.get_idx_split()\n",
    "evaluator = Evaluator(name='ogbn-products')\n",
    "data = dataset[0]\n",
    "\n",
    "x = data.x.to(device)\n",
    "y = data.y.squeeze().to(device)\n",
    "\n",
    "train_idx = split_idx['train']\n",
    "train_loader = NeighborSampler(data.edge_index, node_idx=train_idx,\n",
    "                               sizes=[10, 10, 10], batch_size=512,\n",
    "                               shuffle=True, num_workers=12)\n",
    "subgraph_loader = NeighborSampler(data.edge_index, node_idx=None, sizes=[-1],\n",
    "                                  batch_size=1024, shuffle=False,\n",
    "                                  num_workers=12)\n",
    "\n",
    "out_channels = data.y.max().item() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GAT models on the BA-Shapes dataset\n",
    "from models import GAT_L2_intervention, GAT_L3_intervention\n",
    "\n",
    "# Define several GAT models with 1, 2, 4, 8 attention heads to be used for 'data.pt', and move them to the GPU device (if available)\n",
    "model1_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=1)\n",
    "model2_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=2)\n",
    "model4_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=4)\n",
    "model8_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=8)\n",
    "model1_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=1)\n",
    "model2_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=2)\n",
    "model4_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=4)\n",
    "model8_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=8)\n",
    "\n",
    "# Move the models to the GPU device (if available)\n",
    "model1_L2 = model1_L2.to(device)\n",
    "model2_L2 = model2_L2.to(device)\n",
    "model4_L2 = model4_L2.to(device)\n",
    "model8_L2 = model8_L2.to(device)\n",
    "model1_L3 = model1_L3.to(device)\n",
    "model2_L3 = model2_L3.to(device)\n",
    "model4_L3 = model4_L3.to(device)\n",
    "model8_L3 = model8_L3.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of epochs\n",
    "epochs = 60\n",
    "# Define the learning rate\n",
    "lr = 0.001\n",
    "# Prepare the optimizer\n",
    "optimizer1_L2 = torch.optim.Adam(model1_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer2_L2 = torch.optim.Adam(model2_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer4_L2 = torch.optim.Adam(model4_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer8_L2 = torch.optim.Adam(model8_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer1_L3 = torch.optim.Adam(model1_L3.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer2_L3 = torch.optim.Adam(model2_L3.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer4_L3 = torch.optim.Adam(model4_L3.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer8_L3 = torch.optim.Adam(model8_L3.parameters(), lr=lr, weight_decay=0)\n",
    "\n",
    "# Train the models\n",
    "model1_L2, loss1_L2, acc1_L2 = train_batch(model=model1_L2, train_loader=train_loader, optimizer=optimizer1_L2, epochs=epochs)\n",
    "model2_L2, loss2_L2, acc2_L2 = train_batch(model=model2_L2, train_loader=train_loader, optimizer=optimizer2_L2, epochs=epochs)\n",
    "model4_L2, loss4_L2, acc4_L2 = train_batch(model=model4_L2, train_loader=train_loader, optimizer=optimizer4_L2, epochs=epochs)\n",
    "model8_L2, loss8_L2, acc8_L2 = train_batch(model=model8_L2, train_loader=train_loader, optimizer=optimizer8_L2, epochs=epochs)\n",
    "model1_L3, loss1_L3, acc1_L3 = train_batch(model=model1_L3, train_loader=train_loader, optimizer=optimizer1_L3, epochs=epochs)\n",
    "model2_L3, loss2_L3, acc2_L3 = train_batch(model=model2_L3, train_loader=train_loader, optimizer=optimizer2_L3, epochs=epochs)\n",
    "model4_L3, loss4_L3, acc4_L3 = train_batch(model=model4_L3, train_loader=train_loader, optimizer=optimizer4_L3, epochs=epochs)\n",
    "model8_L3, loss8_L3, acc8_L3 = train_batch(model=model8_L3, train_loader=train_loader, optimizer=optimizer8_L3, epochs=epochs)\n",
    "\n",
    "# Save the model locally\n",
    "torch.save(model1_L2, '/workspace/models/GAT_Products_2L1H.pt')\n",
    "torch.save(model2_L2, '/workspace/models/GAT_Products_2L2H.pt')\n",
    "torch.save(model4_L2, '/workspace/models/GAT_Products_2L4H.pt')\n",
    "torch.save(model8_L2, '/workspace/models/GAT_Products_2L8H.pt')\n",
    "\n",
    "torch.save(model1_L3, '/workspace/models/GAT_Products_3L1H.pt')\n",
    "torch.save(model2_L3, '/workspace/models/GAT_Products_3L2H.pt')\n",
    "torch.save(model4_L3, '/workspace/models/GAT_Products_3L4H.pt')\n",
    "torch.save(model8_L3, '/workspace/models/GAT_Products_3L8H.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss1_L2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspace/[Dataset]OGBN.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f796f6e676d696e5f474154584149227d@ssh-remote%2B7b22686f73744e616d65223a22506572736f6e616c4c616231227d/workspace/%5BDataset%5DOGBN.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m loss1_L2, acc1_L2\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss1_L2' is not defined"
     ]
    }
   ],
   "source": [
    "loss1_L2, acc1_L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GAT_Cora_2L1H, Loss: 1.7192, Train Accuracy: 0.9057, Test Loss: 1.7484, Test Accuracy: 0.8327\n",
      "Model: GAT_Cora_2L2H, Loss: 1.6044, Train Accuracy: 0.9029, Test Loss: 1.6541, Test Accuracy: 0.8327\n",
      "Model: GAT_Cora_2L4H, Loss: 1.3822, Train Accuracy: 0.9100, Test Loss: 1.4581, Test Accuracy: 0.8416\n",
      "Model: GAT_Cora_2L8H, Loss: 1.0693, Train Accuracy: 0.9000, Test Loss: 1.1965, Test Accuracy: 0.8416\n",
      "Model: GAT_Cora_3L1H, Loss: 1.3797, Train Accuracy: 0.8800, Test Loss: 1.4372, Test Accuracy: 0.8098\n",
      "Model: GAT_Cora_3L2H, Loss: 0.8098, Train Accuracy: 0.8957, Test Loss: 0.9117, Test Accuracy: 0.8342\n",
      "Model: GAT_Cora_3L4H, Loss: 0.3302, Train Accuracy: 0.9243, Test Loss: 0.5271, Test Accuracy: 0.8466\n",
      "Model: GAT_Cora_3L8H, Loss: 0.1487, Train Accuracy: 0.9571, Test Loss: 0.5025, Test Accuracy: 0.8476\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "\n",
    "    out = model.inference(x)\n",
    "\n",
    "    y_true = y.cpu().unsqueeze(-1)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "    train_acc = evaluator.eval({\n",
    "        'y_true': y_true[split_idx['train']],\n",
    "        'y_pred': y_pred[split_idx['train']],\n",
    "    })['acc']\n",
    "    val_acc = evaluator.eval({\n",
    "        'y_true': y_true[split_idx['valid']],\n",
    "        'y_pred': y_pred[split_idx['valid']],\n",
    "    })['acc']\n",
    "    test_acc = evaluator.eval({\n",
    "        'y_true': y_true[split_idx['test']],\n",
    "        'y_pred': y_pred[split_idx['test']],\n",
    "    })['acc']\n",
    "\n",
    "    return train_acc, val_acc, test_acc\n",
    "\n",
    "\n",
    "# Test the models\n",
    "test_loss1_L2, test_acc1_L2 = test(model=model1_L2, data=data)\n",
    "test_loss2_L2, test_acc2_L2 = test(model=model2_L2, data=data)\n",
    "test_loss4_L2, test_acc4_L2 = test(model=model4_L2, data=data)\n",
    "test_loss8_L2, test_acc8_L2 = test(model=model8_L2, data=data)\n",
    "test_loss1_L3, test_acc1_L3 = test(model=model1_L3, data=data)\n",
    "test_loss2_L3, test_acc2_L3 = test(model=model2_L3, data=data)\n",
    "test_loss4_L3, test_acc4_L3 = test(model=model4_L3, data=data)\n",
    "test_loss8_L3, test_acc8_L3 = test(model=model8_L3, data=data)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Model: GAT_Cora_2L1H, Loss: {loss1_L2:.4f}, Train Accuracy: {acc1_L2:.4f}, Test Loss: {test_loss1_L2:.4f}, Test Accuracy: {test_acc1_L2:.4f}\")\n",
    "print(f\"Model: GAT_Cora_2L2H, Loss: {loss2_L2:.4f}, Train Accuracy: {acc2_L2:.4f}, Test Loss: {test_loss2_L2:.4f}, Test Accuracy: {test_acc2_L2:.4f}\")\n",
    "print(f\"Model: GAT_Cora_2L4H, Loss: {loss4_L2:.4f}, Train Accuracy: {acc4_L2:.4f}, Test Loss: {test_loss4_L2:.4f}, Test Accuracy: {test_acc4_L2:.4f}\")\n",
    "print(f\"Model: GAT_Cora_2L8H, Loss: {loss8_L2:.4f}, Train Accuracy: {acc8_L2:.4f}, Test Loss: {test_loss8_L2:.4f}, Test Accuracy: {test_acc8_L2:.4f}\")\n",
    "print(f\"Model: GAT_Cora_3L1H, Loss: {loss1_L3:.4f}, Train Accuracy: {acc1_L3:.4f}, Test Loss: {test_loss1_L3:.4f}, Test Accuracy: {test_acc1_L3:.4f}\")\n",
    "print(f\"Model: GAT_Cora_3L2H, Loss: {loss2_L3:.4f}, Train Accuracy: {acc2_L3:.4f}, Test Loss: {test_loss2_L3:.4f}, Test Accuracy: {test_acc2_L3:.4f}\")\n",
    "print(f\"Model: GAT_Cora_3L4H, Loss: {loss4_L3:.4f}, Train Accuracy: {acc4_L3:.4f}, Test Loss: {test_loss4_L3:.4f}, Test Accuracy: {test_acc4_L3:.4f}\")\n",
    "print(f\"Model: GAT_Cora_3L8H, Loss: {loss8_L3:.4f}, Train Accuracy: {acc8_L3:.4f}, Test Loss: {test_loss8_L3:.4f}, Test Accuracy: {test_acc8_L3:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model locally\n",
    "torch.save(model1_L2, '/workspace/GAT_Cora_2L1H.pt')\n",
    "torch.save(model2_L2, '/workspace/GAT_Cora_2L2H.pt')\n",
    "torch.save(model4_L2, '/workspace/GAT_Cora_2L4H.pt')\n",
    "torch.save(model8_L2, '/workspace/GAT_Cora_2L8H.pt')\n",
    "\n",
    "torch.save(model1_L3, '/workspace/GAT_Cora_3L1H.pt')\n",
    "torch.save(model2_L3, '/workspace/GAT_Cora_3L2H.pt')\n",
    "torch.save(model4_L3, '/workspace/GAT_Cora_3L4H.pt')\n",
    "torch.save(model8_L3, '/workspace/GAT_Cora_3L8H.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citeseer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. nodes: 3327 | Num. edges: 9104 | Num. classes: 6 | Num. features: 3703 | Num. train.: 600 | Num. test: 2727\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = 'CiteSeer'\n",
    "transform = T.Compose([T.NormalizeFeatures(),\n",
    "                    T.RandomNodeSplit(split='test_rest', \n",
    "                                    num_train_per_class=100,\n",
    "                                    num_val=0)])\n",
    "path = osp.join(osp.dirname(osp.realpath('/workspace/[Dataset]Citation.ipynb')), '..', 'data', dataset)\n",
    "dataset = Planetoid(path, dataset, transform=transform)\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Print some dataset statistics\n",
    "print(f\"Num. nodes: {data.num_nodes} | Num. edges: {data.num_edges} | Num. classes: {data.y.max() + 1} | Num. features: {data.num_features} | Num. train.: {data.train_mask.sum()} | Num. test: {data.test_mask.sum()}\")\n",
    "# Save to local\n",
    "torch.save(data, \"/workspace/Citeseer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GAT_Citeseer_2L1H, Loss: 1.3092, Train Accuracy: 0.8817, Test Loss: 1.4677, Test Accuracy: 0.7334\n",
      "Model: GAT_Citeseer_2L2H, Loss: 1.0237, Train Accuracy: 0.8883, Test Loss: 1.2675, Test Accuracy: 0.7294\n",
      "Model: GAT_Citeseer_2L4H, Loss: 0.6952, Train Accuracy: 0.8983, Test Loss: 1.0480, Test Accuracy: 0.7319\n",
      "Model: GAT_Citeseer_2L8H, Loss: 0.3951, Train Accuracy: 0.9250, Test Loss: 0.8965, Test Accuracy: 0.7261\n",
      "Model: GAT_Citeseer_3L1H, Loss: 0.5238, Train Accuracy: 0.8783, Test Loss: 0.9247, Test Accuracy: 0.7173\n",
      "Model: GAT_Citeseer_3L2H, Loss: 0.2218, Train Accuracy: 0.9350, Test Loss: 0.9078, Test Accuracy: 0.7140\n",
      "Model: GAT_Citeseer_3L4H, Loss: 0.0866, Train Accuracy: 0.9783, Test Loss: 1.1514, Test Accuracy: 0.6799\n",
      "Model: GAT_Citeseer_3L8H, Loss: 0.0330, Train Accuracy: 0.9933, Test Loss: 1.5214, Test Accuracy: 0.6733\n"
     ]
    }
   ],
   "source": [
    "# Train GAT models on the BA-Shapes dataset\n",
    "from models import GAT_L2_intervention, GAT_L3_intervention\n",
    "\n",
    "out_channels = data.y.max().item() + 1\n",
    "\n",
    "# Define several GAT models with 1, 2, 4, 8 attention heads to be used for 'data.pt', and move them to the GPU device (if available)\n",
    "model1_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=1)\n",
    "model2_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=2)\n",
    "model4_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=4)\n",
    "model8_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=8)\n",
    "model1_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=1)\n",
    "model2_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=2)\n",
    "model4_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=4)\n",
    "model8_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=8)\n",
    "\n",
    "# Move the models to the GPU device (if available)\n",
    "model1_L2 = model1_L2.to(device)\n",
    "model2_L2 = model2_L2.to(device)\n",
    "model4_L2 = model4_L2.to(device)\n",
    "model8_L2 = model8_L2.to(device)\n",
    "model1_L3 = model1_L3.to(device)\n",
    "model2_L3 = model2_L3.to(device)\n",
    "model4_L3 = model4_L3.to(device)\n",
    "model8_L3 = model8_L3.to(device)\n",
    "\n",
    "\"\"\"\n",
    "Now we can train all the models and compare their performance.\n",
    "Keep the number of epochs and the learning rate the same for all the models.\n",
    "\"\"\"\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = 100\n",
    "# Define the learning rate\n",
    "lr = 0.001\n",
    "# Prepare the optimizer\n",
    "optimizer1_L2 = torch.optim.Adam(model1_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer2_L2 = torch.optim.Adam(model2_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer4_L2 = torch.optim.Adam(model4_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer8_L2 = torch.optim.Adam(model8_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer1_L3 = torch.optim.Adam(model1_L3.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer2_L3 = torch.optim.Adam(model2_L3.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer4_L3 = torch.optim.Adam(model4_L3.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer8_L3 = torch.optim.Adam(model8_L3.parameters(), lr=lr, weight_decay=0)\n",
    "\n",
    "# Train the models\n",
    "model1_L2, loss1_L2, acc1_L2 = train(model=model1_L2, data=data, optimizer=optimizer1_L2, epochs=epochs)\n",
    "model2_L2, loss2_L2, acc2_L2 = train(model=model2_L2, data=data, optimizer=optimizer2_L2, epochs=epochs)\n",
    "model4_L2, loss4_L2, acc4_L2 = train(model=model4_L2, data=data, optimizer=optimizer4_L2, epochs=epochs)\n",
    "model8_L2, loss8_L2, acc8_L2 = train(model=model8_L2, data=data, optimizer=optimizer8_L2, epochs=epochs)\n",
    "model1_L3, loss1_L3, acc1_L3 = train(model=model1_L3, data=data, optimizer=optimizer1_L3, epochs=epochs)\n",
    "model2_L3, loss2_L3, acc2_L3 = train(model=model2_L3, data=data, optimizer=optimizer2_L3, epochs=epochs)\n",
    "model4_L3, loss4_L3, acc4_L3 = train(model=model4_L3, data=data, optimizer=optimizer4_L3, epochs=epochs)\n",
    "model8_L3, loss8_L3, acc8_L3 = train(model=model8_L3, data=data, optimizer=optimizer8_L3, epochs=epochs)\n",
    "\n",
    "# Test the models\n",
    "test_loss1_L2, test_acc1_L2 = test(model=model1_L2, data=data)\n",
    "test_loss2_L2, test_acc2_L2 = test(model=model2_L2, data=data)\n",
    "test_loss4_L2, test_acc4_L2 = test(model=model4_L2, data=data)\n",
    "test_loss8_L2, test_acc8_L2 = test(model=model8_L2, data=data)\n",
    "test_loss1_L3, test_acc1_L3 = test(model=model1_L3, data=data)\n",
    "test_loss2_L3, test_acc2_L3 = test(model=model2_L3, data=data)\n",
    "test_loss4_L3, test_acc4_L3 = test(model=model4_L3, data=data)\n",
    "test_loss8_L3, test_acc8_L3 = test(model=model8_L3, data=data)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Model: GAT_Citeseer_2L1H, Loss: {loss1_L2:.4f}, Train Accuracy: {acc1_L2:.4f}, Test Loss: {test_loss1_L2:.4f}, Test Accuracy: {test_acc1_L2:.4f}\")\n",
    "print(f\"Model: GAT_Citeseer_2L2H, Loss: {loss2_L2:.4f}, Train Accuracy: {acc2_L2:.4f}, Test Loss: {test_loss2_L2:.4f}, Test Accuracy: {test_acc2_L2:.4f}\")\n",
    "print(f\"Model: GAT_Citeseer_2L4H, Loss: {loss4_L2:.4f}, Train Accuracy: {acc4_L2:.4f}, Test Loss: {test_loss4_L2:.4f}, Test Accuracy: {test_acc4_L2:.4f}\")\n",
    "print(f\"Model: GAT_Citeseer_2L8H, Loss: {loss8_L2:.4f}, Train Accuracy: {acc8_L2:.4f}, Test Loss: {test_loss8_L2:.4f}, Test Accuracy: {test_acc8_L2:.4f}\")\n",
    "print(f\"Model: GAT_Citeseer_3L1H, Loss: {loss1_L3:.4f}, Train Accuracy: {acc1_L3:.4f}, Test Loss: {test_loss1_L3:.4f}, Test Accuracy: {test_acc1_L3:.4f}\")\n",
    "print(f\"Model: GAT_Citeseer_3L2H, Loss: {loss2_L3:.4f}, Train Accuracy: {acc2_L3:.4f}, Test Loss: {test_loss2_L3:.4f}, Test Accuracy: {test_acc2_L3:.4f}\")\n",
    "print(f\"Model: GAT_Citeseer_3L4H, Loss: {loss4_L3:.4f}, Train Accuracy: {acc4_L3:.4f}, Test Loss: {test_loss4_L3:.4f}, Test Accuracy: {test_acc4_L3:.4f}\")\n",
    "print(f\"Model: GAT_Citeseer_3L8H, Loss: {loss8_L3:.4f}, Train Accuracy: {acc8_L3:.4f}, Test Loss: {test_loss8_L3:.4f}, Test Accuracy: {test_acc8_L3:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model locally\n",
    "torch.save(model1_L2, '/workspace/GAT_Citeseer_2L1H.pt')\n",
    "torch.save(model2_L2, '/workspace/GAT_Citeseer_2L2H.pt')\n",
    "torch.save(model4_L2, '/workspace/GAT_Citeseer_2L4H.pt')\n",
    "torch.save(model8_L2, '/workspace/GAT_Citeseer_2L8H.pt')\n",
    "\n",
    "torch.save(model1_L3, '/workspace/GAT_Citeseer_3L1H.pt')\n",
    "torch.save(model2_L3, '/workspace/GAT_Citeseer_3L2H.pt')\n",
    "torch.save(model4_L3, '/workspace/GAT_Citeseer_3L4H.pt')\n",
    "torch.save(model8_L3, '/workspace/GAT_Citeseer_3L8H.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. nodes: 19717 | Num. edges: 88648 | Num. classes: 3 | Num. features: 500 | Num. train.: 300 | Num. test: 19417\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = 'PubMed'\n",
    "transform = T.Compose([T.NormalizeFeatures(),\n",
    "                    T.RandomNodeSplit(split='test_rest', \n",
    "                                    num_train_per_class=100,\n",
    "                                    num_val=0)])\n",
    "path = osp.join(osp.dirname(osp.realpath('/workspace/[Dataset]Citation.ipynb')), '..', 'data', dataset)\n",
    "dataset = Planetoid(path, dataset, transform=transform)\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Print some dataset statistics\n",
    "print(f\"Num. nodes: {data.num_nodes} | Num. edges: {data.num_edges} | Num. classes: {data.y.max() + 1} | Num. features: {data.num_features} | Num. train.: {data.train_mask.sum()} | Num. test: {data.test_mask.sum()}\")\n",
    "# Save to local\n",
    "torch.save(data, \"/workspace/Pubmed.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GAT_Pubmed_2L1H, Loss: 0.7602, Train Accuracy: 0.8100, Test Loss: 0.8184, Test Accuracy: 0.7316\n",
      "Model: GAT_Pubmed_2L2H, Loss: 0.5968, Train Accuracy: 0.8333, Test Loss: 0.6898, Test Accuracy: 0.7536\n",
      "Model: GAT_Pubmed_2L4H, Loss: 0.4766, Train Accuracy: 0.8500, Test Loss: 0.5984, Test Accuracy: 0.7695\n",
      "Model: GAT_Pubmed_2L8H, Loss: 0.3535, Train Accuracy: 0.8933, Test Loss: 0.5215, Test Accuracy: 0.7948\n",
      "Model: GAT_Pubmed_3L1H, Loss: 0.3548, Train Accuracy: 0.8900, Test Loss: 0.5218, Test Accuracy: 0.7921\n",
      "Model: GAT_Pubmed_3L2H, Loss: 0.2183, Train Accuracy: 0.9300, Test Loss: 0.5265, Test Accuracy: 0.7970\n",
      "Model: GAT_Pubmed_3L4H, Loss: 0.0702, Train Accuracy: 0.9800, Test Loss: 0.7013, Test Accuracy: 0.7751\n",
      "Model: GAT_Pubmed_3L8H, Loss: 0.0224, Train Accuracy: 0.9967, Test Loss: 1.1359, Test Accuracy: 0.7474\n"
     ]
    }
   ],
   "source": [
    "# Train GAT models on the BA-Shapes dataset\n",
    "from models import GAT_L2_intervention, GAT_L3_intervention\n",
    "\n",
    "out_channels = data.y.max().item() + 1\n",
    "\n",
    "# Define several GAT models with 1, 2, 4, 8 attention heads to be used for 'data.pt', and move them to the GPU device (if available)\n",
    "model1_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=1)\n",
    "model2_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=2)\n",
    "model4_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=4)\n",
    "model8_L2 = GAT_L2_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=8)\n",
    "model1_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=1)\n",
    "model2_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=2)\n",
    "model4_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=4)\n",
    "model8_L3 = GAT_L3_intervention(in_channels=data.num_node_features, hidden_channels=64, out_channels=out_channels, heads=8)\n",
    "\n",
    "# Move the models to the GPU device (if available)\n",
    "model1_L2 = model1_L2.to(device)\n",
    "model2_L2 = model2_L2.to(device)\n",
    "model4_L2 = model4_L2.to(device)\n",
    "model8_L2 = model8_L2.to(device)\n",
    "model1_L3 = model1_L3.to(device)\n",
    "model2_L3 = model2_L3.to(device)\n",
    "model4_L3 = model4_L3.to(device)\n",
    "model8_L3 = model8_L3.to(device)\n",
    "\n",
    "\"\"\"\n",
    "Now we can train all the models and compare their performance.\n",
    "Keep the number of epochs and the learning rate the same for all the models.\n",
    "\"\"\"\n",
    "# Define the number of epochs\n",
    "epochs = 100\n",
    "# Define the learning rate\n",
    "lr = 0.001\n",
    "# Prepare the optimizer\n",
    "optimizer1_L2 = torch.optim.Adam(model1_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer2_L2 = torch.optim.Adam(model2_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer4_L2 = torch.optim.Adam(model4_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer8_L2 = torch.optim.Adam(model8_L2.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer1_L3 = torch.optim.Adam(model1_L3.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer2_L3 = torch.optim.Adam(model2_L3.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer4_L3 = torch.optim.Adam(model4_L3.parameters(), lr=lr, weight_decay=0)\n",
    "optimizer8_L3 = torch.optim.Adam(model8_L3.parameters(), lr=lr, weight_decay=0)\n",
    "\n",
    "# Train the models\n",
    "model1_L2, loss1_L2, acc1_L2 = train(model=model1_L2, data=data, optimizer=optimizer1_L2, epochs=epochs)\n",
    "model2_L2, loss2_L2, acc2_L2 = train(model=model2_L2, data=data, optimizer=optimizer2_L2, epochs=epochs)\n",
    "model4_L2, loss4_L2, acc4_L2 = train(model=model4_L2, data=data, optimizer=optimizer4_L2, epochs=epochs)\n",
    "model8_L2, loss8_L2, acc8_L2 = train(model=model8_L2, data=data, optimizer=optimizer8_L2, epochs=epochs)\n",
    "model1_L3, loss1_L3, acc1_L3 = train(model=model1_L3, data=data, optimizer=optimizer1_L3, epochs=epochs)\n",
    "model2_L3, loss2_L3, acc2_L3 = train(model=model2_L3, data=data, optimizer=optimizer2_L3, epochs=epochs)\n",
    "model4_L3, loss4_L3, acc4_L3 = train(model=model4_L3, data=data, optimizer=optimizer4_L3, epochs=epochs)\n",
    "model8_L3, loss8_L3, acc8_L3 = train(model=model8_L3, data=data, optimizer=optimizer8_L3, epochs=epochs)\n",
    "\n",
    "# Test the models\n",
    "test_loss1_L2, test_acc1_L2 = test(model=model1_L2, data=data)\n",
    "test_loss2_L2, test_acc2_L2 = test(model=model2_L2, data=data)\n",
    "test_loss4_L2, test_acc4_L2 = test(model=model4_L2, data=data)\n",
    "test_loss8_L2, test_acc8_L2 = test(model=model8_L2, data=data)\n",
    "test_loss1_L3, test_acc1_L3 = test(model=model1_L3, data=data)\n",
    "test_loss2_L3, test_acc2_L3 = test(model=model2_L3, data=data)\n",
    "test_loss4_L3, test_acc4_L3 = test(model=model4_L3, data=data)\n",
    "test_loss8_L3, test_acc8_L3 = test(model=model8_L3, data=data)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Model: GAT_Pubmed_2L1H, Loss: {loss1_L2:.4f}, Train Accuracy: {acc1_L2:.4f}, Test Loss: {test_loss1_L2:.4f}, Test Accuracy: {test_acc1_L2:.4f}\")\n",
    "print(f\"Model: GAT_Pubmed_2L2H, Loss: {loss2_L2:.4f}, Train Accuracy: {acc2_L2:.4f}, Test Loss: {test_loss2_L2:.4f}, Test Accuracy: {test_acc2_L2:.4f}\")\n",
    "print(f\"Model: GAT_Pubmed_2L4H, Loss: {loss4_L2:.4f}, Train Accuracy: {acc4_L2:.4f}, Test Loss: {test_loss4_L2:.4f}, Test Accuracy: {test_acc4_L2:.4f}\")\n",
    "print(f\"Model: GAT_Pubmed_2L8H, Loss: {loss8_L2:.4f}, Train Accuracy: {acc8_L2:.4f}, Test Loss: {test_loss8_L2:.4f}, Test Accuracy: {test_acc8_L2:.4f}\")\n",
    "print(f\"Model: GAT_Pubmed_3L1H, Loss: {loss1_L3:.4f}, Train Accuracy: {acc1_L3:.4f}, Test Loss: {test_loss1_L3:.4f}, Test Accuracy: {test_acc1_L3:.4f}\")\n",
    "print(f\"Model: GAT_Pubmed_3L2H, Loss: {loss2_L3:.4f}, Train Accuracy: {acc2_L3:.4f}, Test Loss: {test_loss2_L3:.4f}, Test Accuracy: {test_acc2_L3:.4f}\")\n",
    "print(f\"Model: GAT_Pubmed_3L4H, Loss: {loss4_L3:.4f}, Train Accuracy: {acc4_L3:.4f}, Test Loss: {test_loss4_L3:.4f}, Test Accuracy: {test_acc4_L3:.4f}\")\n",
    "print(f\"Model: GAT_Pubmed_3L8H, Loss: {loss8_L3:.4f}, Train Accuracy: {acc8_L3:.4f}, Test Loss: {test_loss8_L3:.4f}, Test Accuracy: {test_acc8_L3:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model locally\n",
    "torch.save(model1_L2, '/workspace/GAT_Pubmed_2L1H.pt')\n",
    "torch.save(model2_L2, '/workspace/GAT_Pubmed_2L2H.pt')\n",
    "torch.save(model4_L2, '/workspace/GAT_Pubmed_2L4H.pt')\n",
    "torch.save(model8_L2, '/workspace/GAT_Pubmed_2L8H.pt')\n",
    "\n",
    "torch.save(model1_L3, '/workspace/GAT_Pubmed_3L1H.pt')\n",
    "torch.save(model2_L3, '/workspace/GAT_Pubmed_3L2H.pt')\n",
    "torch.save(model4_L3, '/workspace/GAT_Pubmed_3L4H.pt')\n",
    "torch.save(model8_L3, '/workspace/GAT_Pubmed_3L8H.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
